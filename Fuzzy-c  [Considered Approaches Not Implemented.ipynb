{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671c85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test=pd.read_csv(r\"C:\\Users\\giovi\\Desktop\\test_df.csv\")\n",
    "train=pd.read_csv(r\"C:\\Users\\giovi\\Desktop\\train_df_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad516d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(columns=['image_id','age','sex','localization','image_path_seg'])\n",
    "train=train.drop(columns=['image_id','age','sex','localization','image_path_seg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8754eeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dx</th>\n",
       "      <th>image_path_iso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nv</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nv</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mel</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nv</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bkl</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>nv</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>bcc</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>mel</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>mel</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>nv</td>\n",
       "      <td>D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2003 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dx                                     image_path_iso\n",
       "0      nv  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "1      nv  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "2     mel  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "3      nv  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "4     bkl  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "...   ...                                                ...\n",
       "1998   nv  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "1999  bcc  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "2000  mel  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "2001  mel  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "2002   nv  D:\\Desktop\\Project\\Isolated_Giuste\\Segmentatio...\n",
       "\n",
       "[2003 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0887fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "# --- Step 1: Caricamento e preprocess ---\n",
    "def load_and_preprocess_image(path, size=(100, 100)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, size)\n",
    "    return img\n",
    "\n",
    "# --- Step 2: Calcolo feature GLCM ---\n",
    "def calculate_glcm_features(img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256):\n",
    "    glcm = graycomatrix(img, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    \n",
    "    contrast = graycoprops(glcm, 'contrast').flatten()\n",
    "    correlation = graycoprops(glcm, 'correlation').flatten()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    energy = graycoprops(glcm, 'energy').flatten()\n",
    "    \n",
    "    features = {\n",
    "        'contrast': np.mean(contrast),\n",
    "        'correlation': np.mean(correlation),\n",
    "        'homogeneity': np.mean(homogeneity),\n",
    "        'energy': np.mean(energy),\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# --- Step 3: Estrazione features dataset ---\n",
    "def extract_features_from_dataset(df):\n",
    "    features_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        img = load_and_preprocess_image(row['image_path_iso'])\n",
    "        feats = calculate_glcm_features(img)\n",
    "        feats['dx'] = row['dx']\n",
    "        features_list.append(feats)\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# --- Step 4: Fuzzy C-means clustering per classe ---\n",
    "def fuzzy_c_means_per_class(df_train_feats, m=2, error=0.005, maxiter=1000):\n",
    "    classes = df_train_feats['dx'].unique()\n",
    "    cluster_centers_per_class = {}\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_data = df_train_feats[df_train_feats['dx'] == cls].drop(columns=['dx']).values.T  # (features, samples)\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "            cls_data, c=1, m=m, error=error, maxiter=maxiter, init=None\n",
    "        )\n",
    "        cluster_centers_per_class[cls] = cntr.flatten()\n",
    "    return cluster_centers_per_class\n",
    "\n",
    "# --- Funzione per stampare centroidi fuzzy di una classe specifica ---\n",
    "def print_fuzzy_centroids_for_class(cluster_centers, class_name):\n",
    "    if class_name not in cluster_centers:\n",
    "        print(f\"Classe '{class_name}' non trovata nei cluster.\")\n",
    "        return\n",
    "    \n",
    "    centroid = cluster_centers[class_name]\n",
    "    features = ['contrast', 'correlation', 'homogeneity', 'energy']\n",
    "    print(f\"Centroidi fuzzy per la classe '{class_name}':\")\n",
    "    for feat, val in zip(features, centroid):\n",
    "        print(f\"  {feat}: {val:.4f}\")\n",
    "\n",
    "# --- Step 5: Distanza Chi-quadrato ---\n",
    "def chi_square_distance(test_feats, cluster_center):\n",
    "    numerator = (test_feats - cluster_center)**2\n",
    "    denominator = test_feats + cluster_center + 1e-10  # evita divisione per zero\n",
    "    return np.sum(numerator / denominator)\n",
    "\n",
    "# --- Step 6: Classificazione immagine ---\n",
    "def classify_image(test_feats, cluster_centers):\n",
    "    distances = {}\n",
    "    for cls, center in cluster_centers.items():\n",
    "        dist = chi_square_distance(test_feats, center)\n",
    "        distances[cls] = dist\n",
    "    predicted_class = min(distances, key=distances.get)\n",
    "    return predicted_class, distances\n",
    "\n",
    "# --- Pipeline completa ---\n",
    "def run_pipeline(df_train, df_test):\n",
    "    # Estrai feature train e test\n",
    "    print(\"Estrazione feature training set...\")\n",
    "    train_features = extract_features_from_dataset(df_train)\n",
    "    print(\"Estrazione feature test set...\")\n",
    "    test_features = extract_features_from_dataset(df_test)\n",
    "\n",
    "    # Applica fuzzy c-means clustering su train\n",
    "    print(\"Esecuzione fuzzy c-means clustering per classe...\")\n",
    "    cluster_centers = fuzzy_c_means_per_class(train_features)\n",
    "\n",
    "    # Classifica immagini di test\n",
    "    print(\"Classificazione immagini di test...\")\n",
    "    preds = []\n",
    "    for idx, row in test_features.iterrows():\n",
    "        feats = row.drop('dx').values\n",
    "        pred_class, _ = classify_image(feats, cluster_centers)\n",
    "        preds.append(pred_class)\n",
    "    test_features['predicted'] = preds\n",
    "\n",
    "    # Calcola metriche\n",
    "    accuracy = (test_features['dx'] == test_features['predicted']).mean()\n",
    "    num_errors = (test_features['dx'] != test_features['predicted']).sum()\n",
    "    num_tests = len(test_features)\n",
    "    error_percent = (num_errors / num_tests) * 100\n",
    "    efficiency = 100 - error_percent\n",
    "\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    print(f'Error rate: {error_percent:.2f}%')\n",
    "    print(f'Efficiency: {efficiency:.2f}%')\n",
    "\n",
    "    return cluster_centers, test_features\n",
    "\n",
    "# --- USO ---\n",
    "# cluster_centers, test_results = run_pipeline(df_train, df_test)\n",
    "# print_fuzzy_centroids_for_class(cluster_centers, 'Angioedema')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae19ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrazione feature training set...\n",
      "Estrazione feature test set...\n",
      "Esecuzione fuzzy c-means clustering per classe...\n",
      "Classificazione immagini di test...\n",
      "Accuracy: 16.18%\n",
      "Error rate: 83.82%\n",
      "Efficiency: 16.18%\n"
     ]
    }
   ],
   "source": [
    "cluster_centers, test_results = run_pipeline(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b27da2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroidi fuzzy per la classe 'nv':\n",
      "  contrast: 373.0522\n",
      "  correlation: 0.9110\n",
      "  homogeneity: 0.7391\n",
      "  energy: 0.7135\n"
     ]
    }
   ],
   "source": [
    "print_fuzzy_centroids_for_class(cluster_centers, 'nv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
